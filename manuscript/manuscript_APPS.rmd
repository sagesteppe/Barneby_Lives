--- 
title: BarnebyLives':' an R package to create herbarium specimen labels and digital data sheets
author:  |
    | Reed Clark Benkendorf$^1$^[Correspondence: rbenkendorf@chicagobotanic.org], Jeremie B. Fant$^1$$^,$$^2$
    |  $^1$Chicago Botanic Garden, 1000 Lake Cook Road, Glencoe, Illinois 60022, USA  
    |  $^2$Plant Biology and Conservation, Northwestern University, Evanston, Illinois 60208, USA  
abstract:  |  
  **Premise:** Depositing specimens to herbaria is a time consuming task. Many institutions have reduced the amount of funding for herbaria, and universities have reduced the amount of education dedicated to curatorial tasks and specimen deposition. Despite this, the continual generation of herbaria specimens are essential for research in ecology and evolution. In order to faciliate the continued growth of herbaria BarnebyLives was developed as tool to supplement collection notes, perform geographic and, taxonomic informatic processes, enact spell checks and produce labels.    
  **Methods and Results:** BarnebyLives uses geospatial data from the U.S. Census Bureau to provide political jurisdiction information, and data from other sources, including the United States Geological Survey, to supplement collection notes by providing information on abiotic site conditions. It uses inhouse spell checks to verify the spelling of a collection at all taxonomic ranks, the IPNI standard author database to check standard author abbreviations, and the Royal Botanic Garden Kews 'Plants of the World Online' to check for nomenclatural innovations. Optionally the package writes driving directions to sites using Google Maps. Finally the package outputs data in a tabular format for review by the user to accept or confirm changes,      
  **Conclusions:** BarnebyLives provides accurate political and physical information, reduces typos, provides users the most current taxonomic opinions, generates driving directions to sites, and produces aesthetically appealing labels and shipping manifests in a matter of minutes.     
keywords: |
  Herbarium, collections, natural history museum, geospatial, automation, R, software
output:
  pdf_document: default
  toc: no
  word_document: default
csl: "../citations/american-journal-of-botany.csl"
bibliography: ../citations/citations.bib
link-citations: yes
fig_caption: yes
always_allow_html: yes
header-includes:
- \usepackage{endfloat}
- \usepackage{setspace}\doublespacing
- \usepackage{lineno}
- \linenumbers
- \usepackage[width=\textwidth]{caption}
- \usepackage{wrapfig}
- \usepackage[export]{adjustbox}
--- 

```{r echo = F}
knitr::opts_chunk$set(echo=F, warning = F, message = F)
```

Nearly 400 million specimens are housed in herbaria around the world (@thiers2021herbaria).
These specimens were collected with the goal of describing the plant kingdoms taxonomic diversity, and documenting the worlds floristic diversity (@greve2016realising). 
The rate of accessioning new collections to herbaria diminished in the 20th century as research goals in the biological sciences shifted away from describing, documenting, and understanding earths biodiversity (@prather2004decline, @pyke2010biological, @daru2018widespread).
Which, among other factors, lead to a decline in the amount of funding allocated to collections based research, and the number of staff maintaining and accessioning new collections (@funk2014erosion). 
Fortunately, renewed interest in collections have brought herbaria of all sizes back to the forefront of plant sciences (@ronsted2020integrative, @marsico2020small).  

Recent innovations in computing, specimen digitization, data sharing, DNA sequencing, and statistics have brought about a renaissance in herbarium based studies (@greve2016realising, @james2018herbarium, @brewer2019factors, @ronsted2020integrative). 
Current uses of specimen based data extend far beyond their traditional roles in systematics and floristics, and studies utilizing collections are regularly carried out to better understand the ecological niches, phenological processes, and interactions of plants (@ronsted2020integrative). 
However, we anticipate that collections will gain their most widespread utilization as natural history is being revitalized in ecology, via novel approaches, such as remote sensing, meta-barcoding, community science, electronic sensing (@tosa2021rapid).

However, we now stand at a time where we recognize the need for more specimens, but are in a difficult position where the skills of collecting and processing specimens, and time allocated for collecting, have declined among young persons (@daru2018widespread, @mishler2020spatial).
The submittal of specimens to herbaria is a, well documented albeit time consuming process, especially for younger collectors with limited experience in the process. 
While many young collectors, who are capable of using dichotomous keys to reliably identify their collections, exist we have observed that they face difficulties navigating several aspects of data collection. 
This scenario results in not only the delay in the deposition of many specimens, but undoubtedly the deposition of many collections at all.
Problems which young collectors face generally include both the lack of dedicated time awarded to them at a seasons end to process specimens, and a general lack of formal education on cartography, natural history, taxonomy, and plant systematics.

The successful generation of an herbarium specimen includes many steps which are easy to take for granted. 
For example, while the acquisition of political information for a collection site appears simple, it is only so if the collector has the adequate resources at their disposal. 
Given the association of boundaries with topographically complex areas (e.g. watersheds) it often requires topographic maps, which are no longer widespread - resulting in many having difficulties interpreting them, or transcription of coordinates into a Geographic Information System (e.g. ArcMap, which is relatively expensive at 100$ year), or more likely Google Maps by individual site. 
This lack of topographic maps compounds the issues of young collectors being unable to come up with appropriate site names. 

Here we provide a description of the BarnebyLives R package. 
BarnebyLives was named for plant taxonomist extraordinaire Rupert Charles Barneby (1911-200), whom published over 6,500 pages of text, described over 750 taxa, and is notable for balancing his studies at the Willian & Lynda Steere Herbarium at the New York Botanical Garden with annual collection trips in Western North America from 1937-1970, and sporadically until his passing (@welsh2001rupert). 
Select accolades of Rupert include the Asa Gray Award from the American Society of Plant Taxonomists (ASPT) in 1989, the 1991 Engler Silver Medal from the International Association of Plant Taxonomists (IAPT), as well as being one of eight recipients of the International Botanical Congresses's (IBC) Millenium Botany Award (1999) (@welsh2001rupert).

\begin{wrapfigure}{l}{0.35\textwidth}
  \centering
    \includegraphics[max size={\textwidth}{\textheight}]{../graphics/plots/flowchart-trim.png}
  \caption{Recommended workflow.}
\end{wrapfigure}

More evidently difficult tasks involve taxonomy and the rapid rate at which taxonomic names have changed since the publication of many Floras. 

# METHODS AND RESULTS

`r lorem::ipsum(paragraphs = 5)`

```{r install package}
devtools::install_github('sagesteppe/BarnebyLives')
```


```{r load libraries}
library(tidyverse) # data operations
library(BarnebyLives) # for helping accession collections
```

## Usage
All steps of BarnebyLives except for label generation are run from within Rstudio. 
Data may be read in from any common spreadsheet management system or database connection such as Excel, LibreOffice, OpenOffice, or via the cloud on Googlesheets. 
The latter two options are documented here and in package vignettes, detailed descriptions of the required and suggested input columns are located on the Github page (https://github.com/sagesteppe/BarnebyLives *'Input Data Column Names'*) and over 100 real-world examples are on a Google Sheets accessible from the page.
BarnebyLives is atypical of R packages in that it requires a considerable amount of data to operate (Table 1).
Virtually all of the on-disk memory associated with these data are for storing geo-spatial information, setting up a local instance of the program - at whichever scale a user desires (see Figure XX) is available in the package documentation. Functions which require the on-disk data require a path to the data as an argument. 
Manually supplying the argument allows for the users to judiciously decide a storage location suitable for there needs.  
We anticipate most personal BarnebyLives instances will be less than several gigabytes, and the processing takes relatively little RAM, hence we believe installations can work on hardware as small as Chromebooks, or have the data stored entirely on thumb-drives.
The final steps of Barnebylives, generating the labels require working installations of Rmarkdown, a LaTeX installation (e.g. pdflatex, lualatex, xelatex), and the open source command line tools pdfjam and pdftk.
While these steps are run through bash, we have wrapped them in a R functions which bypass the need to enter the commands to a terminal.
Several commands in BarnebyLives require the output from previous functions, and a workflow which satisfies these requirements is presented in FIGURE XX. 

```{r import example data and gather some summaries}

data <- read.csv('data/test_data.csv', na.strings = "") %>% 
  drop_na(c('Longitude', 'Latitude', 'Date_digital')) %>% 
  unite(col = 'Scientific_name', c(Binomial, Infrarank, Infraspecies), na.rm=TRUE, sep = " ", remove = F)

n_families <- data %>% 
  group_by(Family) %>% 
  count() %>% 
  nrow() # 74 families

n_spp <- data %>% 
  group_by(Binomial) %>% 
  count() %>% 
  nrow() # 616 species

n_infraspecies <- data %>% 
  drop_na(Infraspecies) %>% 
  group_by(Binomial, Infraspecies) %>% 
  count() %>% 
  nrow() # 66 distinct infraspecies

n_sp_authors <- data %>% 
  drop_na(Binomial_authority) %>% 
  count() %>% # 557 groups of authors
  pull()

n_infra_sp_auths <- data %>% 
  drop_na(Infraspecific_authority) %>% 
  group_by(Binomial, Infraspecies) %>% 
  count() %>% 
  nrow() # 22 distinct infra species author groups

# number of collection sites

n_sites <- data %>% 
  distinct(Latitude, Longitude) %>% 
  nrow()

```

\begin{wrapfigure}{r}{0.35\textwidth}
  \centering
    \includegraphics[width=0.35\textwidth]{../graphics/plots/collections_map-trim.png}
  \caption{The spatial extent (orange), and herbarium collection sites (burgundy) tested in this manuscript.}
\end{wrapfigure}

### Herbarium Collections

The package was finalized using the primary authors collections from 2023. The testing of the package within this manuscript was performed using a subset of their collections from 2018-2022, *all* of which are un-accessioned. Only collections which had identifications to the level of species or lower, and transcribed collection dates and coordinates were used. This results in a data set of `r nrow(data)` records for testing, from `r n_sites` sites located across Western North America FIGURE XX. In total `r n_spp` species (with `r n_sp_authors` authorships), with `r n_infraspecies` infraspecies (`r n_infra_sp_auths` authorships) in `r n_families` families were used for testing. 

```{r Run pipeline with all steps and benchmarking, eval = F}

time_split_binomials <- system.time({ # split up names into their components
  data <- split_binomial(data, 'Scientific_name')
})

time_dms2dd <- system.time({ # if necessary convert coordinates in degrees minutes second to decimal degrees
  data <- dms2dd(data, dms = F)
})

time_autofill_checker <- system.time({ # has the spreadsheet software auto-incremented coordinate values?
  data <- autofill_checker(data)
})

time_coords2sf <- system.time({ # create a spatial (simple features) object
  data <- coords2sf(data)
})

p2geo <- '/media/steppe/hdd/Barneby_Lives-dev/geodata'

time_political_grabber <- system.time({ # grab political information for collection
  data <- political_grabber(data, y = 'Collection_number', path = p2geo)
})

time_physical_grabber <- system.time({ # grab sites physical information
  data <- physical_grabber(data, path = p2geo)
})

time_site_writer <- system.time({ # write site location notes
  data <- site_writer(data, path = p2geo)
})

p2tax <- '/media/steppe/hdd/Barneby_Lives-dev/taxonomic_data'

time_spell_check <- system.time({ # ensure appropriate spellings of the species
  sct <- spell_check(data, column = 'Full_name', path = p2tax)
})

time_family_spell_check <- system.time({ # ensure appropriate spelling of the family
  data <- family_spell_check(data, path = p2tax)
})

time_author_check <- system.time({ # ensure authorities are spelled-noted correctly
  data <- author_check(data, path = p2tax)
})

time_associate_dropper <- system.time({ # remove the focal taxon from the noted associates
  data <- associate_dropper(data, 'Full_name')
})

time_date_parser <- system.time({ # parse dates into museum formats
  data <- date_parser(data, coll_date = 'Date_digital')
})

time_geodata_writer <- system.time({ # write out collection as GoogleEarth object
  geodata_writer(data, path = 'data/processed', 
               filename = 'Herbarium_Collections_2023',
               filetype = 'kml')
})

rm(p2geo, p2tax)
```

```{r Run the API services, eval = F}

# we keep these processes in a discrete chunk set not to evaluate so as to not overwhelm
# the services. Google does charge if the number of queries per month is high.

time_powo_searcher <- system.time({ # search for synonyms from plants of the world online
  
 names <- sf::st_drop_geometry(data) %>% 
   pull(Full_name)

 pow_res <- lapply(names,
       powo_searcher) %>% 
       bind_rows()
 data <- bind_cols(data, pow_res)

 rm(names, pow_res)
}) # has been run

saveRDS(time_powo_searcher, file = 'data/processed/time_powo_searcher')
saveRDS(data, file = 'data/processed/data_w_POWO_search')

time_directions_grabber <- system.time({ # write directions to sites
  SoS_gkey = Sys.getenv("Sos_gkey")
  data <- directions_grabber(data, api_key = SoS_gkey)
})

saveRDS(time_directions_grabber, file = 'data/processed/time_directions_grabber')
saveRDS(data, file = 'data/processed/data_w_Google_Maps')
```

```{r Total Time of operations, eval = F}

time_powo_searcher <- readRDS(file = 'data/processed/time_powo_searcher')
time_directions_grabber <- readRDS('data/processed/time_directions_grabber')

time_trials <- data.frame(as.matrix(do.call(rbind, mget(ls(pattern = '^time'))))) %>% 
  rownames_to_column('Function') %>% 
  select(-user.child, -sys.child) %>% 
  mutate(Function = str_remove(Function, 'time_')) %>% 
  mutate(Module = case_when(
    Function %in% c('associate_dropper', 'split_binomials', 'date_parser') ~ 'Style',
    Function %in% c('autofill_checker', 'coords2sf', 'dms2dd', 'physical_grabber', 
                    'political_grabber', 'site_writer', 'geodata_writer', 'directions_grabber') ~ 'Geospatial', 
    Function %in% c('spell_check', 'family_spell_check', 'author_check',  'powo_searcher') ~ 'Taxonomic',
    Function %in% c('time_label_maker', 'time_shipping_manifest', 'time_label_assembly') ~ 'Labels'
    ),
    Group = if_else(Function %in% c('powo_searcher', 'directions_grabber'), 'Online', 'Local')
  ) 
  
# save these as RDS so operations do not need to be run each time document knits
saveRDS(time_trials, file = 'data/processed/time_trials')

rm(time_trials)
rm(list=ls(pattern = 'time'))
```

```{r load in time trials}
time_trials <- readRDS('data/processed/time_trials')
tt_local <- time_trials[time_trials$Group=='Local',]
```

It took roughly *six* minutes (`r sum( time_trials[time_trials$Group=='Local', 'elapsed'])`s) to run all local steps of BarnebyLives, and roughly 20 minutes (`r time_trials[time_trials$Function=='powo_searcher', 'elapsed']`s) to search Plants of the World Online, and `r time_trials[time_trials$Function=='directions_grabber', 'elapsed']` to search Google Maps and write directions to sites.
Most of the local run time is attributable to the spatial (spatial: `r sum(tt_local[tt_local$Module=='Geospatial', 'elapsed'])`s), and taxonomic operations (`r sum(tt_local[tt_local$Module=='Taxonomic', 'elapsed'])`), style: `r sum(tt_local[tt_local$Module=='Style', 'elapsed'])`. 
The spell check operation of the scientific name accounted for nearly all of the time (`r sum(tt_local[tt_local$Function=='spell_check', 'elapsed'])`) spent performing local taxonomic operations.
The generation of labels consumed around XX minutes for the rendering, XX to combine individual labels four per single sheet of landscape orientated paper, and XX to combine the XX sheets to a single Portable Document Format (PDF).  

```{r}
rm(time_trials, tt_local)
```

## Results

```{r import results}
data_p <- readRDS(file = 'data/processed/data_w_POWO_search') %>% 
  sf::st_drop_geometry()

drop_na(data_p, Binomial_authority) %>% 
  nrow() # nearly all relating to the absence/presence of a period

drop_na(data_p, Infra_auth_issues) %>% 
  nrow() # nearly all relating to the absence/presence of a period

long_flag <- drop_na(data_p, Long_AutoFill_Flag) %>% 
  nrow() # 4 auto fill cases

lat_flag <- drop_na(data_p, Lat_AutoFill_Flag) %>% 
  nrow() # 2 autofill cases

## Family spell check; this is a comparision of my input spelling, and the results
## of the family spell check function

Family_in_positions <- data_p %>% 
  drop_na(Family)
Family_in <- Family_in_positions %>% 
  filter(Collection_number %in% data_p$Collection_number) %>% 
  arrange(Collection_number) %>% 
  pull(Family)

Family_out <- data_p %>% 
  filter(Collection_number %in% Family_in_positions$Collection_number) %>% 
  pull(Family)
Family_in[ which( Family_in != Family_out ) ]


## Family Level Results
# these species were found by POW, and according to POW, the species are in the f
# following families. 
data_p %>% 
  sf::st_drop_geometry() %>% 
  filter(POW_Family != 'NOT FOUND') %>% 
  filter(POW_Family != Family) %>% 
  select(Collection_number, Full_name, Family, POW_Family) %>% 
  mutate(Situation = 
    case_when(
      Family == 'Hydrophyllaceae' ~ 'Preferred', 
      Family %in% c('Plantaginaceae', 'Athyriaceae') ~ 'Outdated',
      Family %in% c('Saxifragaceae', 'Solanaceae') ~ 'Submitter_Incorrect', 
      Family == 'Bataceae' ~ 'Internal Error', 
      .default = 'Typo'
    ))

data_p %>% 
  sf::st_drop_geometry() %>% 
  filter(POW_Genus == 'NOT FOUND') %>% 
  select(Collection_number, Full_name, Genus, POW_Genus) 

# how many of my genera were mis-spelled??
data_p %>% 
  sf::st_drop_geometry() %>% 
  filter(POW_Genus != 'NOT FOUND') %>% 
  filter(POW_Genus != Genus) 

# the mismatch between POW genus and not
data_p %>% 
  sf::st_drop_geometry() %>% 
  filter(POW_Genus != 'NOT FOUND') %>% 
  filter(POW_Genus != Genus) %>% 
  select(Collection_number, Full_name, Genus, POW_Genus) %>% 
  mutate(Situation = 
    case_when(
      Genus %in% c('Pleuraphis', 'Glandularia') ~ 'Preferred', # check Pleuraphis, i am confused on this still....
      Genus %in% c('Oenothera', 'Cryptantha', 'Ivesia', 'Lotus', 'Polygala', 'Minuartia',
                    'Pseudostellaria', 'Achnatherum', 'Scirpus', 'Peritoma', 'Arenaria', 
                    'Spartina', 'Polygonum', 'Atriplex', 'Cymopterus', 'Trisetum', 'Bahia', 
                   'Oryzopsis', 'Potentilla', 'Pascopyrum'
                    ) ~ 'Outdated',
      Genus %in% c('Vaccinium', 'Eleocharis') ~ 'Internal Error',
      .default = 'Typo'
    ),
    Situation = if_else(Full_name == 'Oenothera caespitosa Nutt.', 'Internal Error', Situation))

#data_p %>% 
#  filter(Binomial_authority != POW_Name_authority)

data_p %>% 
  sf::st_drop_geometry() %>% 
  filter(Epithet != POW_Epithet ) %>% 
  select(Collection_number, Full_name, Epithet, POW_Epithet) 

```

Even on data which had been manually cleaned and error-checked by a human several times BarnebyLives was able to reduce transcription errors, identify typos, make nomenclature suggestions, and reformat text elements for downstream use. The number of family misspellings were XX (% percent), the number of misspelled genera were XX (% percent), the number of misspelled binomials were XX (% percent). The number of author abbreviations which were not in the appropriate format were XX (% percent), in nearly all cases the presence or absence of a period were the issue. Plants of the World Online was able to identify XX new names for the submitted taxa, XX of which the author adopted. `r long_flag` records were appropriately flagged for issues with auto fill incrementation of the longitude value, and `r lat_flag` records were also auto-flagged for increases in latitude values (% of records).

\begin{wrapfigure}{r}{0.45\textwidth}
  \centering
    \includegraphics[width=0.45\textwidth]{../graphics/tables/Screenshot-DataSources.png}
  \caption{Sources of Data required for operations}
\end{wrapfigure}

\newpage
# CONCLUSIONS
BarnebyLives is a tool which is able to rapidly acquire relevant geographic, and taxonomic data. It is also capable of performing specialized spell checks, and assorted curatorial tasks to produce both digital and analog data. The package relies on no licensed Software, such as the Microsoft suite, and is suitable for install on all major operating systems (Windows, Mac, Linux), with a small amount of use of the command line, which may be called from the Rstudio rather than a 'traditional' terminal.

# AUTHOR CONTRIBUTIONS
The project was conceptualized by R.C.B. The program was written by R.C.B. Data collection and analysis were performed by R.C.B. R.C.B. wrote the manuscript with input from all other authors. All authors approved the final version of the manuscript.

# ACKNOWLEDGEMENTS
The Bureau of Land Management are graciously acknowledged as providers of funding to R.C.B for the majority of his specimen collection activities. Two anonymous peer reviewers who increased the quality of this manuscript are thanked. Several prominent associated collectors of specimens used in this study are thanked: Dani Yashinovitz, Dakota Becerra, Hannah Lovell, Caitlin Miller & Hubert Szczygiel. 

# DATA AVAILABILITY STATEMENT
The BarnebyLives R package is open source, the development version is available on GitHub (https://github.com/sagesteppe/BarnebyLives), and the stable version is available on CRAN. The package includes three real use-case vignettes (tutorials) on usage. One vignette "setting_up_files" explores setting up a instance for a certain geographic area. Another vignette "running_pipeline" showcases the usage of the package for processing data entered on a spreadsheet. A final vignette "creating_labels" shows the usage of an R, and Bash script launched from RStudio to produce print-ready labels. All data used in this mansucript are available at: https://github.com/sagesteppe/Barneby_Lives_dev/manuscript

# ORCID
Jeremie Fant https://orcid.org/0000-0001-9276-1111  

\small
# REFERENCES

<div id="refs"></div>

# SUPPORTING INFORMATION
Additional supporting information can be found online in the Supporting Information section at the end of this article. 

**Appendix S1.** A table of all time trials for each function.
