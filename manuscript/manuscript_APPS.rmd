--- 
title: 'BarnebyLives: an R package to create herbarium specimen labels and clean spreadsheets'
author:  |
    | Reed Clark Benkendorf$^1$^[Author for Correspondence: rbenkendorf@chicagobotanic.org], Jeremie B. Fant$^1$$^,$$^2$
    |  $^1$Chicago Botanic Garden, 1000 Lake Cook Road, Glencoe, Illinois 60022, USA  
    |  $^2$Plant Biology and Conservation, Northwestern University, Evanston, Illinois 60208, USA  
abstract: |
  **Premise:** Depositing specimens to herbaria is a time consuming task. Many institutions have reduced the amount of funding for herbaria, and universities have reduced the amount of education dedicated to curatorial tasks and specimen deposition. Despite this, the continual generation of herbaria specimens are essential for current and future research in evolution and ecology. In order to faciliate the continued growth of herbaria BarnebyLives was developed as tool to supplement collection notes, perform geographic and, taxonomic informatic processes, enact spell checks, produce labels, and submit digital data.    
  **Methods and Results:** BarnebyLives uses geospatial data from the U.S. Census Bureau to provide political jurisdiction information, and data from other sources, including the United States Geological Survey, to supplement collection notes by providing information on abiotic site conditions. It uses inhouse spell checks to verify the spelling of a collection at all taxonomic ranks, the IPNI standard author database to check standard author abbreviations, and the Royal Botanic Garden Kews 'Plants of the World Online' to check for nomenclatural innovations. Optionally the package writes driving directions to sites using Google Maps. The package outputs data in a tabular format for review by the user to accept or confirm changes, before dynamically rendering labels.       
  **Conclusions:** BarnebyLives provides accurate political and physical information, reduces typos, provides users the most current taxonomic opinions, generates driving directions to sites, and produces aesthetically appealing labels and shipping manifests in a matter of minutes.     
keywords: |
  herbariaum, natural history museum, collections, geospatial, automation, R, software 
output:
  pdf_document: default
  toc: no
  word_document: default
csl: "../citations/american-journal-of-botany.csl"
bibliography: ../citations/citations.bib
link-citations: yes
fig_caption: yes
always_allow_html: yes
header-includes:
- \usepackage{endfloat}
- \usepackage{setspace}\doublespacing
- \usepackage{lineno}
- \linenumbers
- \usepackage[width=\textwidth]{caption}
- \usepackage{wrapfig}
- \usepackage[export]{adjustbox}
--- 

```{r echo = F}
knitr::opts_chunk$set(echo=F, warning = F, message = F)
```

Nearly 400 million specimens are housed in herbaria around the globe (@thiers2021herbaria).
These specimens, collected to describe the taxonomic diversity of plants and document the worlds floristic diversity, have recently found myriad new applications in several adjacent fields such as conservation biology and ecology (@greve2016realising, @james2018herbarium, @brewer2019factors, @ronsted2020integrative). 
However, The rate of accessioning new collections to herbaria diminished in the 20^th^ century as priorities in biology shifted away from describing and documenting earths biodiversity towards understanding cellular and molecular processes (@prather2004decline, @pyke2010biological, @daru2018widespread).
This shift, among other factors, lead to a decline in the funding allocated to collections based research, the number of staff maintaining and accessioning new collections, and educating students in these practices (@funk2014erosion). 
Fortunately, renewed interest approaches in collections generated by 'big data approaches' have brought herbarium collections back to the forefront of the natural sciences (@ronsted2020integrative, @marsico2020small).  

In fact innovations in computing, specimen digitization, data sharing, DNA sequencing, and statistics have likely brought about greater use of herbarium specimens than ever before (@greve2016realising, @james2018herbarium, @brewer2019factors, @ronsted2020integrative). 
The current uses of specimen based data extend far beyond their traditional roles in systematics and floristics, and studies utilizing collections are regularly carried out to better understand the ecological niches, phenological processes, and interactions of plants (@ronsted2020integrative, @davis2023herbarium). 
Further we anticipate that collections are yet to gain their most widespread utilization as a revitalization of natural history appears underway in ecology, fostered via novel approaches such as remote and electronic sensing, meta-barcoding, and community science  (@tosa2021rapid). 
While image or purely observational (rather than collections based) citizen science initializes (e.g. iNaturalist) have dovetailed to meet many needs of these studies specimens contain rich data which are not accessible via images. 
Namely specimens have the ability to: provide samples of DNA, secondary metabolites, or proteins, notes on the status and composition of the biotic and abiotic settings at time of collection, material for measuring (micro-)morphological attributes (@borges2020schrodinger), and seeds or pollen; eternally ensuing specimens as the ultimate data source to center most efforts around.

However, despite this renewed recognition of the utility of collections, efforts to continually grow them appear slow (@prather2004decline). 
We conjecture this is in part because collecting and depositing specimens is a fundamentally slower process, especially for novice collectors, than simply taking photographs via well-developed apps (@daru2018widespread, @mishler2020spatial). 
While many young botanists, capable of using dichotomous keys to reliably identify - and able to collect satisfactory - material exist, we have observed that they face difficulties navigating several aspects of data collection and preparation of labels for submission to herbaria. 
Apparent problems include the lack of dedicated time at a field seasons end to process specimens, a general lack of education on cartography and orienteering, natural history (e.g. geology, geomorphology), nomenclature and Latin, various computer programs (e.g. Microsoft Office suite), and increasingly - plant systematics (@nanglu2023nature, @woodland2007botanists, @barrows2016crossroads). 
In the absence of suitable mentors this assuredly results in not only the delay in the deposition of many specimens, but undoubtedly in a failure for many specimens to be accessioned at all, and increasingly ever collected. 

\begin{wrapfigure}{l}{0.35\textwidth}
  \centering
    \includegraphics[max size={\textwidth}{\textheight}]{../graphics/plots/flowchart-trim.png}
  \caption{Recommended workflow.}
\end{wrapfigure}

The generation of an herbarium specimen includes many steps which are easy to take for granted (@forman1989herbarium). 
For example while acquiring appropriate political information for a collection site appears simple, young collectors rarely have the adequate resources (printed topographic maps, or GIS software) at their disposal. 
In topographically complex areas, where borders are often associated with hydrologic basins and the ridges defining them, collectors are liable to misinterpret their position. 
Finding appropriate sites names is another problem which can rarely be solved without a printed map, as many software maps now consider many features which would serve as site names extraneous in the era of GPS. 
The rate at which taxonomic innovations are occurring has left many Floras difficult for young users to interpret and has made it difficult for them to find more recently applied names.
Upon finding a name they may find it frustrating to hear that while published, the proposal has been accepted by few practitioners and they have unwittingly offended certain curators. 
Formatting a label correctly (e.g. abbreviations), if successful upon even setting up a mail merge, is a time consuming process and likely to introduce several errors in formatting. 
Even if a collector navigates all of these hurdles successfully, the time allocated to each step is quite large. 
Further each step of interfacing with different resources increases the opportunity for transcription errors. 

Here we provide a description of the BarnebyLives R package. 
BarnebyLives aims to increase both the data quality of labels, and to speed up the process of producing them. 
It rapidly provides political and administrative boundary information for a collection site using data from the U.S. Census Bureau (@walker2022tigris), the Public Land Survey System, and ownership details of public lands via the Protected-Areas Database (PAD-US) from (@usgs2024padus). 
Site names are suggested via finding the closest unambiguously named place feature via the Geographic Name Information System (GNIS), and by precise calculation of the distance and azimuth from these localities to the collection site (@gnis2024). 
Using the GMBA Mountain Inventory V. 2, a standardized named mountain data set with global coverage, which we have supplemented with over XXXX valleys allows for a relevant descriptor of the general region without any ambiguity (@snethlage2022hierarchical). 
Spell checks on all scientific names (including associated species) are performed using a copy of the World Checklist of Vascular Plants, and the collected species may be searched via Kew's Plant of the World Online for relevant synonyms (@govaerts2021world, @powo2024). 
Author abbreviations are verified using IPNI's Standard Author Abbreviation Checklist and also returned by Kew's Plants of the World Online to ensure proper abbreviation of authorities (@ipni2024, @powo2024). 
Checks are performed to search for common issues associated with spreadsheets, or transcription, such as the auto-filling of coordinate and date columns. 
After final review of the data generated by the package, it allows for the option to export spreadsheets which are usable for mass upload of data to multiple common herbarium databases, as well as the generation of herbarium labels. 

Here we provide a description of the BarnebyLives R package. 
BarnebyLives was named for plant taxonomist Rupert Charles Barneby (1911-2000), whom published over 6,500 pages of text, described over 750 taxa, and is notable for balancing his studies at the William & Lynda Steere Herbarium at the New York Botanical Garden with annual collection trips in Western North America from 1937-1970, and sporadically until his passing in 2000 (@welsh2001rupert). 
Select accolades of Rupert include the 1989 Asa Gray Award from the American Society of Plant Taxonomists (ASPT), the 1991 Engler Silver Medal from the International Association of Plant Taxonomists (IAPT), as well as being one of eight recipients of the International Botanical Congress's (IBC) Millennium Botany Award (1999) (@welsh2001rupert). 
Most importantly, Rupert was remembered as being generous with his time to assist younger botanists with the more arcane aspects of field botany and taxonomy (@holmgren2017). 

# METHODS AND RESULTS

```{r install package}
## devtools::install_github('sagesteppe/BarnebyLives')
```

```{r load libraries}
library(tidyverse) # data operations
library(BarnebyLives) # for helping accession collections
```

## Usage
All steps of BarnebyLives except for label generation are run from within Rstudio. 
Data may be read in from any common spreadsheet management system or database connection such as Excel, or free of charge alternatives such as: LibreOffice, OpenOffice, or via the cloud on Googlesheets. 
The latter two options are documented here and in package vignettes, detailed descriptions of the required and suggested input columns are located on the Github page (https://github.com/sagesteppe/BarnebyLives *'Input Data Column Names'*) and over 100 real-world examples are on a Google Sheets accessible from the page.
BarnebyLives is atypical of R packages in that it requires a considerable amount of data to operate (Table 1).
Virtually all of the on-disk memory associated with these data are for storing spatial data, setting up a local instance of the program - at whichever scale a user desires (see Figure XX) is fully documented in the package documentation. 
Functions which require the on-disk data require a path to the data as an argument.  
Manually supplying the path argument allows for users to judiciously decide a storage location suitable for their needs.  
We anticipate most personal BarnebyLives instances will be less than several gigabytes (ours covering all of the conterminous Western U.S. is XX GiB), and the processing takes relatively little RAM, hence we believe installations can work on hardware as limited as Chromebooks, while having the data stored entirely on thumb-drives.
The final steps of Barnebylives, generating the labels require working installations of Rmarkdown, a LaTeX installation (e.g. pdflatex, lualatex, xelatex), and the open source command line tools pdfjam and pdftk.
While these steps are run through bash, we have wrapped them in R functions which bypass the need to enter the commands to a terminal.
Several commands in BarnebyLives require the output from previous functions, and a workflow which satisfies these requirements is presented in Figure 1. 

```{r import example data and gather some summaries}

data <- read.csv('data/test_data.csv', na.strings = "") %>% 
  drop_na(c('Longitude', 'Latitude', 'Date_digital')) %>% 
  unite(col = 'Scientific_name', c(Binomial, Infrarank, Infraspecies), na.rm=TRUE, sep = " ", remove = F)

n_families <- data %>% 
  group_by(Family) %>% 
  count() %>% 
  nrow() # 74 families

n_spp <- data %>% 
  group_by(Binomial) %>% 
  count() %>% 
  nrow() # 616 species

n_infraspecies <- data %>% 
  drop_na(Infraspecies) %>% 
  group_by(Binomial, Infraspecies) %>% 
  count() %>% 
  nrow() # 66 distinct infraspecies

n_sp_authors <- data %>% 
  drop_na(Binomial_authority) %>% 
  count() %>% # 557 groups of authors
  pull()

n_infra_sp_auths <- data %>% 
  drop_na(Infraspecific_authority) %>% 
  group_by(Binomial, Infraspecies) %>% 
  count() %>% 
  nrow() # 22 distinct infra species author groups

# number of collection sites

n_sites <- data %>% 
  distinct(Latitude, Longitude) %>% 
  nrow()

```

\begin{wrapfigure}{r}{0.35\textwidth}
  \centering
    \includegraphics[width=0.35\textwidth]{../graphics/plots/collections_map-trim.png}
  \caption{The spatial extent (orange), and herbarium collection sites (burgundy) tested in this manuscript.}
\end{wrapfigure}

### Herbarium Collections

The package was finalized using the primary authors collections from 2023. 
The testing of the package within this manuscript was performed using a subset of their collections from 2018-2022, *all* of which are un-accessioned. 
Only collections which had identifications to the level of species or lower, and transcribed collection dates and coordinates were used. 
This results in a data set of `r nrow(data)` records for testing, from `r n_sites` sites located across Western North America (Figure 2). In total `r n_spp` species (with `r n_sp_authors` sets of authors), with `r n_infraspecies` infraspecies (`r n_infra_sp_auths` authors) in `r n_families` families were used for testing. 

```{r Run pipeline with all steps and benchmarking, eval = F}

time_split_binomials <- system.time({ # split up names into their components
  data <- split_binomial(data, 'Scientific_name')
})

time_dms2dd <- system.time({ # if necessary convert coordinates in degrees minutes second to decimal degrees
  data <- dms2dd(data, dms = F)
}) 

time_autofill_checker <- system.time({ # has the spreadsheet software auto-incremented coordinate values?
  data <- autofill_checker(data)
})

time_coords2sf <- system.time({ # create a spatial (simple features) object
  data <- coords2sf(data)
})

p2geo <- '/media/steppe/hdd/Barneby_Lives-dev/geodata'

time_political_grabber <- system.time({ # grab political information for collection
  data <- political_grabber(data, y = 'Collection_number', path = p2geo)
})

time_physical_grabber <- system.time({ # grab sites physical information
  data <- physical_grabber(data, path = p2geo)
})

time_site_writer <- system.time({ # write site location notes
  data <- site_writer(data, path = p2geo)
})

p2tax <- '/media/steppe/hdd/Barneby_Lives-dev/taxonomic_data'

time_spell_check <- system.time({ # ensure appropriate spellings of the species
  data <- spell_check(data, column = 'Full_name', path = p2tax)
})

time_family_spell_check <- system.time({ # ensure appropriate spelling of the family
  data <- family_spell_check(data, path = p2tax)
})

time_author_check <- system.time({ # ensure authorities are spelled-noted correctly
  data <- author_check(data, path = p2tax)
})

time_associate_dropper <- system.time({ # remove the focal taxon from the noted associates
  data <- associate_dropper(data, 'Full_name')
})

time_date_parser <- system.time({ # parse dates into museum formats
  data <- date_parser(data, coll_date = 'Date_digital')
})

time_geodata_writer <- system.time({ # write out collection as GoogleEarth object
  geodata_writer(data, path = 'data/processed', 
               filename = 'Herbarium_Collections_2023',
               filetype = 'kml')
})

rm(p2geo, p2tax)
```

```{r Run the API services, eval = F}

# we keep these processes in a discrete chunk set not to evaluate so as to not overwhelm
# the services. Google does charge if the number of queries per month isnt high.

time_powo_searcher <- system.time({ # search for synonyms from plants of the world online
  
 names <- sf::st_drop_geometry(data) %>% 
   pull(SpellCk.taxon_name)

 pow_res <- lapply(names,
       powo_searcher) %>% 
       bind_rows()
 data <- bind_cols(data, pow_res) |>
  dplyr::relocate(geometry, .after = dplyr::last_col()) |>
  sf::st_as_sf(crs = 4326)

 rm(names, pow_res)
}) # has been run

saveRDS(time_powo_searcher, file = 'data/processed/time_powo_searcher')
saveRDS(data, file = 'data/processed/data_w_POWO_search')

time_directions_grabber <- system.time({ # write directions to sites
  SoS_gkey = Sys.getenv("Sos_gkey")
  data <- directions_grabber(data, api_key = SoS_gkey)
})

saveRDS(time_directions_grabber, file = 'data/processed/time_directions_grabber')
saveRDS(data, file = 'data/processed/data_w_Google_Maps')
```

```{r Total Time of operations, eval = F}

time_powo_searcher <- readRDS(file = 'data/processed/time_powo_searcher')
time_directions_grabber <- readRDS('data/processed/time_directions_grabber')

time_trials <- data.frame(as.matrix(do.call(rbind, mget(ls(pattern = '^time'))))) %>% 
  rownames_to_column('Function') %>% 
  select(-user.child, -sys.child) %>% 
  mutate(Function = str_remove(Function, 'time_')) %>% 
  mutate(Module = case_when(
    Function %in% c('associate_dropper', 'split_binomials', 'date_parser') ~ 'Style',
    Function %in% c('autofill_checker', 'coords2sf', 'dms2dd', 'physical_grabber', 
                    'political_grabber', 'site_writer', 'geodata_writer', 'directions_grabber') ~ 'Geospatial', 
    Function %in% c('spell_check', 'family_spell_check', 'author_check',  'powo_searcher') ~ 'Taxonomic',
    Function %in% c('time_label_maker', 'time_shipping_manifest', 'time_label_assembly') ~ 'Labels'
    ),
    Group = if_else(Function %in% c('powo_searcher', 'directions_grabber'), 'Online', 'Local')
  ) 
  
# save these as RDS so operations do not need to be run each time document knits
saveRDS(time_trials, file = 'data/processed/time_trials')

rm(time_trials)
rm(list=ls(pattern = 'time'))
```

```{r load in time trials}
time_trials <- readRDS('data/processed/time_trials')
tt_local <- time_trials[time_trials$Group=='Local',]

time_label_gen <- readRDS('data/processed/time_label_gen')[['elapsed']]
time_4perpage <- gsub('user.*$', '', readLines('labels/4labsperpage.txt'))[1]
time_final <- gsub('user.*$', '', readLines('labels/process2final.txt'))[1]

minutemen <- function(x){
  lkp <- 1:60
  names(lkp) <-  c('one', 'two', 'three', 'four', 'five', 'six', 
         'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve', 13:60)
  
  names(lkp) [ round(x/60, digits = 0) ]
}
```

BarnebyLives took roughly `r minutemen(sum( time_trials[time_trials$Group=='Local', 'elapsed']))` minutes (`r sum( time_trials[time_trials$Group=='Local', 'elapsed'])`s) to run all local steps, and roughly `r minutemen(time_trials[time_trials$Function=='powo_searcher', 'elapsed'])` minutes (`r time_trials[time_trials$Function=='powo_searcher', 'elapsed']`s) to search Plants of the World Online, and `r time_trials[time_trials$Function=='directions_grabber', 'elapsed']`s to search Google Maps and write directions to sites. 
Most of the local run time is attributable to the spatial (spatial: `r sum(tt_local[tt_local$Module=='Geospatial', 'elapsed'])`s), and taxonomic operations (`r sum(tt_local[tt_local$Module=='Taxonomic', 'elapsed'])`s), style: `r sum(tt_local[tt_local$Module=='Style', 'elapsed'])`s. 
The spell check operation of the scientific name accounted for nearly all of the time (`r sum(tt_local[tt_local$Function=='spell_check', 'elapsed'])`s) spent performing local taxonomic operations.
The generation of labels consumed around `r minutemen(time_label_gen)` minutes (`r time_label_gen`s) for the rendering, `r time_4perpage`s to combine individual labels four per single sheet of landscape orientated paper, and `r time_final`s to combine the `r length(list.files('labels/processed'))` sheets to a single Portable Document Format (PDF).  
The total computer run time for processing these XXX specimens was XX minutes. 


```{r}
rm(time_trials, tt_local)
```

## Results

```{r import results}
data_p <- readRDS(file = 'data/processed/data_w_POWO_search') %>% 
  sf::st_drop_geometry()

no_binomial_auth_issues <- drop_na(data_p, Binomial_authority) %>% 
  nrow() # nearly all relating to the absence/presence of a period

no_infra_auth_issues <- drop_na(data_p, Infra_auth_issues) %>% 
  nrow() # nearly all relating to the absence/presence of a period

long_flag <- drop_na(data_p, Long_AutoFill_Flag) %>% 
  nrow() # 4 auto fill cases

lat_flag <- drop_na(data_p, Lat_AutoFill_Flag) %>% 
  nrow() # 2 autofill cases

## Family spell check; this is a comparision of my input spelling, and the results
## of the family spell check function

Family_in_positions <- data_p %>% 
  drop_na(Family)
Family_in <- Family_in_positions %>% 
  filter(Collection_number %in% data_p$Collection_number) %>% 
  arrange(Collection_number) %>% 
  pull(Family)

Family_out <- data_p %>% 
  filter(Collection_number %in% Family_in_positions$Collection_number) %>% 
  pull(Family)
Family_in[ which( Family_in != Family_out ) ]

## Family Level Results
# these species were found by POW, and according to POW, the species are in the f
# following families. 
family_incongruence <- data_p %>% 
  sf::st_drop_geometry() %>% 
  filter(POW_Family != 'NOT FOUND') %>% 
  filter(POW_Family != Family) %>% 
  select(Collection_number, Full_name, Family, POW_Family) %>% 
  mutate(Situation = 
    case_when(
      Family %in% c('Hydrophyllaceae', 'Namaceae') ~ 'Preferred', 
      Family %in% c('Athyriaceae') ~ 'Outdated',
      Family %in% c('Saxifragaceae', 'Plantaginaceae') ~ 'Submitter_Incorrect', 
      Family %in% c('Bataceae', 'Ericaceae') ~ 'Internal_Error', 
      .default = 'Typo'
    ))

# how many of my genera were mis-spelled??
genera_mispelled <- data_p %>% 
  sf::st_drop_geometry() %>% 
  filter(POW_Genus == 'NOT FOUND') %>% 
  select(Collection_number, Full_name, Genus, POW_Genus) 

# the mismatch between POW genus and not
genus_mismatch <- data_p %>% 
  sf::st_drop_geometry() %>% 
  filter(POW_Genus != 'NOT FOUND') %>% 
  filter(POW_Genus != Genus) %>% 
  select(Collection_number, Full_name, Genus, POW_Genus) %>% 
  mutate(Situation = 
    case_when(
      Genus %in% c('Glandularia', 'Oenothera', 'Chamerion') ~ 'Preferred',
      # check Pleuraphis, i am confused on this still....
      Genus %in% c('Cryptantha', 'Ivesia', 'Lotus', 'Polygala', 'Minuartia', 'Pleuraphis',
                    'Pseudostellaria', 'Achnatherum', 'Scirpus', 'Peritoma', 'Arenaria', 
                    'Spartina', 'Polygonum', 'Atriplex', 'Cymopterus', 'Trisetum', 'Bahia', 
                   'Oryzopsis', 'Potentilla', 'Pascopyrum'
                    ) ~ 'Outdated',
      Genus %in% c('Vaccinium', 'Eleocharis') ~ 'Internal_Error',
      .default = 'Typo'
    ),
    Situation = if_else(Full_name == 'Oenothera caespitosa Nutt.', 'Internal_Error', Situation))

binom_auth_difference <- data_p %>% 
  filter(Binomial_authority != POW_Name_authority)

epithet_diff <- data_p %>% 
  sf::st_drop_geometry() %>% 
  filter(Epithet != POW_Epithet, !Full_name %in% genus_mismatch$Full_name) %>% 
  select(Collection_number, Full_name, Epithet, POW_Genus, POW_Epithet, POW_Infraspecies) %>% 
  distinct(Full_name, .keep_all = T) %>%  # do we record repeat collections ?
  mutate(Situation = 
           case_when(
             Collection_number %in% c(
               '1217', '1251', '1283', '1311', '1337', '1391', '1450', '1576', 
               '1594', '1745', '2043', '2086', '2108', '2109', '2120', '2127', '2130',
               '2153', '2199', '2227', '2242', '2256', '2289', '2370', '2379', 
               '2393', '2415', '2511', '2573', '2648', '2660', '2687', '2690',
               '2710', '2715', '2750', '2767', '2818')
             ~ 'Spelling',
             Collection_number %in% c('1207') ~ 'Binomial_Reversed', 
             Collection_number %in% c('1588', '2445', '2777', '1337', '2412', '2748', 
                                      '2652', '2805', '2194', '2040', '2039', '2403',
                                      '2328', '2076') ~ 'Outdated',
             Collection_number %in% c('2644') ~ 'Incorrect',
             Collection_number %in% c('2326', '2038', '1424', '2618',
                                      '2665', '2297', '2343') ~ 'Internal_Error',
             Collection_number %in% c('2110') ~ 'Preferred',
             Collection_number %in% c('2480', '2561', '2727') ~ 'Not Found'
             
           )
  )

rm(Family_in, Family_out)
```

Even on data which had been manually cleaned and error-checked by a human several times BarnebyLives was able to reduce transcription errors, identify typos, make nomenclature suggestions, and reformat text elements for downstream use. While no families were misspelled, BL made `r nrow(family_incongruence)` suggestions on naming, `r sum(family_incongruence$Situation=='Typo', na.rm = T)` manually entered typos were found, it identified `r sum(family_incongruence$Situation=='Submitter_Incorrect', na.rm = T)` instances where an incorrect family was entered, and `r sum(family_incongruence$Situation=='Outdated', na.rm = T)` instances of an outdated circumscription applied. BL flagged `r sum(family_incongruence$Situation=='Preferred', na.rm = T)` records where the author follows an alternative taxonomy, and flagged `r sum(family_incongruence$Situation=='Internal_Error', na.rm = T)` records in error.

BL identified `r nrow(genus_mismatch)` discrepancies at the level of genus between user submitted and processed data. 
In `r sum(genus_mismatch$Situation=='Outdated')` of these instances the user supplied an outdated name instance of an outdated circumscription applied (`r nrow(unique(genus_mismatch[genus_mismatch$Situation=='Outdated', 'Genus']))` genera total). BL flagged `r sum(genus_mismatch$Situation=='Preferred', na.rm = T)` records where the author follows an alternative taxonomy (`r nrow(unique(genus_mismatch[genus_mismatch$Situation=='Preferred', 'Genus']))` genera total), and flagged `r sum(genus_mismatch$Situation=='Internal_Error', na.rm = T)` record in error.

BL flagged 75 species 

The number of author abbreviations which were not in the appropriate format were XX (% percent), in nearly all cases the presence or absence of a period were the issue. Plants of the World Online was able to identify XX new names for the submitted taxa, XX of which the author adopted. `r long_flag` records were appropriately flagged for issues with auto fill increment of the longitude value, and `r lat_flag` records were also auto-flagged for increases in latitude values (% of records).

```{r}
rm(genus_mismatch, genera_mispelled, family_incongruence)
```

\begin{wrapfigure}{r}{0.45\textwidth}
  \centering
    \includegraphics[width=0.40\textwidth]{../graphics/tables/Screenshot-DataSources.png}
  \caption{Sources of Data required for operations}
\end{wrapfigure}

# CONCLUSIONS
BarnebyLives is a tool which is able to rapidly acquire relevant geographic, and taxonomic data. 
It is also capable of performing specialized spell checks, and assorted curatorial tasks to produce both digital and analog data. 
The package relies on no licensed Software, such as the Microsoft suite, and is suitable for install on all major operating systems (Windows, Mac, Linux), with a small amount of use of the command line, which may be called from the Rstudio rather than a 'traditional' terminal.

# AUTHOR CONTRIBUTIONS
The project was conceptualized by R.C.B. The program was written by R.C.B.
Data collection and analysis were performed by R.C.B.
R.C.B. wrote the manuscript with input from all other authors. 
All authors approved the final version of the manuscript.

# ACKNOWLEDGEMENTS
The Bureau of Land Management are graciously acknowledged as providers of funding to R.C.B for the majority of his specimen collection activities. 
Two anonymous peer reviewers who increased the quality of this manuscript are thanked. 
Sofia Garcia is acknowledged for creating the 'Valleys' data set which place naming in the package relies on. 
Several prominent associated collectors of specimens used in this study are thanked: Dani Yashinovitz, Dakota Becerra, Hannah Lovell, Caitlin Miller & Hubert Szczygiel. 

# DATA AVAILABILITY STATEMENT
The BarnebyLives R package is open source, the development version is available on GitHub (https://github.com/sagesteppe/BarnebyLives), and the stable version is available on CRAN. 
The package includes three real use-case vignettes (tutorials) on usage. 
One vignette "setting_up_files" explores setting up a instance for a certain geographic area. 
Another vignette "running_pipeline" showcases the usage of the package for processing data entered on a spreadsheet. 
A final vignette "creating_labels" shows the usage of an R, and Bash script launched from RStudio to produce print-ready labels. 
All data used in this manuscript are available at: https://github.com/sagesteppe/Barneby_Lives_dev/manuscript

# ORCID
Reed Benkendorf https://orcid.org/0000-0003-3110-6687  
Jeremie Fant https://orcid.org/0000-0001-9276-1111  

\small
# REFERENCES

<div id="refs"></div>

# SUPPORTING INFORMATION
Additional supporting information can be found online in the Supporting Information section at the end of this article. 

**Appendix S1.** A table of all time trials for each function.
